{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Training the Vision Transformer on a Custom Dataset.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2efb606ae85043d2aec636657b8dc23c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_1b6366fa2570491f852ca70c8dd78a3b",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_39b0a4ffae63427ba7e1b688e5a6d011",
       "IPY_MODEL_12fcdc8b8f9c4c14836f67a8012d43f7"
      ]
     },
     "model_module_version": "1.5.0"
    },
    "1b6366fa2570491f852ca70c8dd78a3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "39b0a4ffae63427ba7e1b688e5a6d011": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_1fd362b69c9d44f58239aeb5080705c6",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 425,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 425,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_4a0ebf07f34641d5b059e0def5d92d41"
     },
     "model_module_version": "1.5.0"
    },
    "12fcdc8b8f9c4c14836f67a8012d43f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d7ae2eb9cdf24069ad682092497e0bfe",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 425/425 [00:23&lt;00:00, 18.1B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_c6a703307fa84008a1a651a0bde9aff9"
     },
     "model_module_version": "1.5.0"
    },
    "1fd362b69c9d44f58239aeb5080705c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "4a0ebf07f34641d5b059e0def5d92d41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "d7ae2eb9cdf24069ad682092497e0bfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "c6a703307fa84008a1a651a0bde9aff9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "36a2eee270944e1ea01101031a0e430c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_1ab261bd567b47f593bef7559d7140e5",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_f60180a0cd674bb2b8842f6f174613b1",
       "IPY_MODEL_6f521b76233846d8a09ee7ab98f7ea03"
      ]
     },
     "model_module_version": "1.5.0"
    },
    "1ab261bd567b47f593bef7559d7140e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "f60180a0cd674bb2b8842f6f174613b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_cf4f03a541d94ab29d4825910471cf27",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 345636463,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 345636463,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_6715a58a5d564ebf8bf64b705cf6f76c"
     },
     "model_module_version": "1.5.0"
    },
    "6f521b76233846d8a09ee7ab98f7ea03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_495a2c6efc654ff29bbcbe1a7ba1e41e",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 346M/346M [00:23&lt;00:00, 15.0MB/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_0b5c8cf671ca4cb09703ee9dde8766c9"
     },
     "model_module_version": "1.5.0"
    },
    "cf4f03a541d94ab29d4825910471cf27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "6715a58a5d564ebf8bf64b705cf6f76c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "495a2c6efc654ff29bbcbe1a7ba1e41e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "0b5c8cf671ca4cb09703ee9dde8766c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "d54bd61599c740ce9afbd6dd0cdf3918": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_6373a61866e8427899a8c56ac463fc88",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_892ab87763ca4569b1c14c7a864f0327",
       "IPY_MODEL_f9ccf45eaeae49cd9ab55c8524fd06f7"
      ]
     },
     "model_module_version": "1.5.0"
    },
    "6373a61866e8427899a8c56ac463fc88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "892ab87763ca4569b1c14c7a864f0327": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_598d0a9ff37e4051a77fe32e33c89d69",
      "_dom_classes": [],
      "description": "Downloading: 100%",
      "_model_name": "FloatProgressModel",
      "bar_style": "success",
      "max": 160,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 160,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_1de61920e64e41c8ba8da72e7ef9e27d"
     },
     "model_module_version": "1.5.0"
    },
    "f9ccf45eaeae49cd9ab55c8524fd06f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_f69783a89ebf4887aa55388c5f936d3b",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 160/160 [00:07&lt;00:00, 20.7B/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_a6023bb8327044c4a6b478656261ef7d"
     },
     "model_module_version": "1.5.0"
    },
    "598d0a9ff37e4051a77fe32e33c89d69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "initial",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "1de61920e64e41c8ba8da72e7ef9e27d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    },
    "f69783a89ebf4887aa55388c5f936d3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     },
     "model_module_version": "1.5.0"
    },
    "a6023bb8327044c4a6b478656261ef7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     },
     "model_module_version": "1.2.0"
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "kgn-a3NiSjqR"
   },
   "source": [
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_ds = torchvision.datasets.ImageFolder('./Train', transform=ToTensor())\n",
    "valid_ds = torchvision.datasets.ImageFolder('./Test', transform=ToTensor())\n",
    "test_ds = torchvision.datasets.ImageFolder('./Val', transform=ToTensor())"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = # need to add labels "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cGDrb1Q4ToLN"
   },
   "source": [
    "from transformers import ViTModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ViTForImageClassification(nn.Module):\n",
    "    def __init__(self, num_labels=8):\n",
    "        super(ViTForImageClassification, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.vit.config.hidden_size, num_labels)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def forward(self, pixel_values, labels):\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        output = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "          loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        if loss is not None:\n",
    "          return logits, loss.item()\n",
    "        else:\n",
    "          return logits, None"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ntGvS0_wUAxc"
   },
   "source": [
    "# hyper parameters\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 2e-5"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At9H-QOStt8_"
   },
   "source": [
    "pretrained Vision Transformer feature extractor, an Adam Optimizer, and a Cross Entropy Loss function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "2efb606ae85043d2aec636657b8dc23c",
      "1b6366fa2570491f852ca70c8dd78a3b",
      "39b0a4ffae63427ba7e1b688e5a6d011",
      "12fcdc8b8f9c4c14836f67a8012d43f7",
      "1fd362b69c9d44f58239aeb5080705c6",
      "4a0ebf07f34641d5b059e0def5d92d41",
      "d7ae2eb9cdf24069ad682092497e0bfe",
      "c6a703307fa84008a1a651a0bde9aff9",
      "36a2eee270944e1ea01101031a0e430c",
      "1ab261bd567b47f593bef7559d7140e5",
      "f60180a0cd674bb2b8842f6f174613b1",
      "6f521b76233846d8a09ee7ab98f7ea03",
      "cf4f03a541d94ab29d4825910471cf27",
      "6715a58a5d564ebf8bf64b705cf6f76c",
      "495a2c6efc654ff29bbcbe1a7ba1e41e",
      "0b5c8cf671ca4cb09703ee9dde8766c9",
      "d54bd61599c740ce9afbd6dd0cdf3918",
      "6373a61866e8427899a8c56ac463fc88",
      "892ab87763ca4569b1c14c7a864f0327",
      "f9ccf45eaeae49cd9ab55c8524fd06f7",
      "598d0a9ff37e4051a77fe32e33c89d69",
      "1de61920e64e41c8ba8da72e7ef9e27d",
      "f69783a89ebf4887aa55388c5f936d3b",
      "a6023bb8327044c4a6b478656261ef7d"
     ]
    },
    "id": "RIyJr8EDtvlR",
    "outputId": "1e4b58b2-ade2-4d6f-858b-8578ae8ea736"
   },
   "source": [
    "from transformers import ViTFeatureExtractor\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# Define Model\n",
    "model = ViTForImageClassification(len(train_ds.classes))    \n",
    "# Feature Extractor\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "# Adam Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "# Cross Entropy Loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# Use GPU if available  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda() "
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTZ-BP1yu1Us"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ql2T5PDUI1D",
    "outputId": "ea0f05df-577b-4e15-f18a-5775824e838d"
   },
   "source": [
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "print(\"Number of train samples: \", len(train_ds))\n",
    "print(\"Number of test samples: \", len(test_ds))\n",
    "print(\"Detected Classes are: \", train_ds.class_to_idx) \n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_loader  = data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) \n",
    "\n",
    "# Train the model\n",
    "for epoch in range(EPOCHS):        \n",
    "  for step, (x, y) in enumerate(train_loader):\n",
    "    # Change input array into list with each batch being one element\n",
    "    x = np.split(np.squeeze(np.array(x)), BATCH_SIZE)\n",
    "    # Remove unecessary dimension\n",
    "    for index, array in enumerate(x):\n",
    "      x[index] = np.squeeze(array)\n",
    "    # Apply feature extractor, stack back into 1 tensor and then convert to tensor\n",
    "    x = torch.tensor(np.stack(feature_extractor(x)['pixel_values'], axis=0))\n",
    "    # Send to GPU if available\n",
    "    x, y  = x.to(device), y.to(device)\n",
    "    b_x = Variable(x)   # batch x (image)\n",
    "    b_y = Variable(y)   # batch y (target)\n",
    "    # Feed through model\n",
    "    output, loss = model(b_x, labels)\n",
    "    # Calculate loss\n",
    "    if loss is None: \n",
    "      loss = loss_func(output, b_y)   \n",
    "      optimizer.zero_grad()           \n",
    "      loss.backward()                 \n",
    "      optimizer.step()\n",
    "\n",
    "    if step % 50 == 0:\n",
    "      # Get the next batch for testing purposes\n",
    "      test = next(iter(test_loader))\n",
    "      test_x = test[0]\n",
    "      # Reshape and get feature matrices as needed\n",
    "      test_x = np.split(np.squeeze(np.array(test_x)), BATCH_SIZE)\n",
    "      for index, array in enumerate(test_x):\n",
    "        test_x[index] = np.squeeze(array)\n",
    "      test_x = torch.tensor(np.stack(feature_extractor(test_x)['pixel_values'], axis=0))\n",
    "      # Send to appropirate computing device\n",
    "      test_x = test_x.to(device)\n",
    "      test_y = test[1].to(device)\n",
    "      # Get output (+ respective class) and compare to target\n",
    "      test_output, loss = model(test_x, test_y)\n",
    "      test_output = test_output.argmax(1)\n",
    "      # Calculate Accuracy\n",
    "      accuracy = (test_output == test_y).sum().item() / BATCH_SIZE\n",
    "      print('Epoch: ', epoch, '| train loss: %.4f' % loss, '| test accuracy: %.2f' % accuracy)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples:  21133\n",
      "Number of test samples:  2289\n",
      "Detected Classes are:  {'AN01-20210104-154854': 0, 'AN01-20210104-155349': 1, 'AN01-20210104-155828': 2, 'AN01-20210104-160254': 3, 'AN01-20210104-160616': 4, 'AN02-20210107-130959': 5, 'AN02-20210107-131328': 6, 'AN02-20210107-131701': 7, 'AN02-20210107-132038': 8, 'AN02-20210107-132433': 9}\n",
      "Epoch:  0 | train loss: 2.3634 | test accuracy: 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-a8be4ecb95e7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     19\u001B[0m       \u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;31m# Apply feature extractor, stack back into 1 tensor and then convert to tensor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 21\u001B[1;33m     \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfeature_extractor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'pixel_values'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     22\u001B[0m     \u001B[1;31m# Send to GPU if available\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m  \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, images, return_tensors, **kwargs)\u001B[0m\n\u001B[0;32m    139\u001B[0m         \u001B[1;31m# transformations (resizing + normalization)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_resize\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresample\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_normalize\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m             \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_mean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_std\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    139\u001B[0m         \u001B[1;31m# transformations (resizing + normalization)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_resize\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresample\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresample\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_normalize\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m             \u001B[0mimages\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_mean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_std\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\transformers\\image_utils.py\u001B[0m in \u001B[0;36mresize\u001B[1;34m(self, image, size, resample, default_to_square, max_size)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    217\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPIL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 218\u001B[1;33m             \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_pil_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    219\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\transformers\\image_utils.py\u001B[0m in \u001B[0;36mto_pil_image\u001B[1;34m(self, image, rescale)\u001B[0m\n\u001B[0;32m    114\u001B[0m                 \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m255\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m             \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 116\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mPIL\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfromarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mimage\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mfromarray\u001B[1;34m(obj, mode)\u001B[0m\n\u001B[0;32m   2791\u001B[0m             \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtostring\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2792\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2793\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrombuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"raw\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrawmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2794\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2795\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mfrombuffer\u001B[1;34m(mode, size, data, decoder_name, *args)\u001B[0m\n\u001B[0;32m   2731\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2732\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2733\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mfrombytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2734\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2735\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mfrombytes\u001B[1;34m(mode, size, data, decoder_name, *args)\u001B[0m\n\u001B[0;32m   2676\u001B[0m         \u001B[0margs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2677\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2678\u001B[1;33m     \u001B[0mim\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnew\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2679\u001B[0m     \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrombytes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecoder_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2680\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\AI-CUDA\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mnew\u001B[1;34m(mode, size, color)\u001B[0m\n\u001B[0;32m   2640\u001B[0m         \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpalette\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImagePalette\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mImagePalette\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2641\u001B[0m         \u001B[0mcolor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpalette\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetcolor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2642\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mim\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_new\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfill\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2643\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2644\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWXvWiB-srBC"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "ZLv_xdYssuGO",
    "outputId": "734efe1c-371c-4714-be8a-a79f0eceaefd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "EVAL_BATCH = 1\n",
    "eval_loader  = data.DataLoader(valid_ds, batch_size=EVAL_BATCH, shuffle=True, num_workers=4) \n",
    "# Disable grad\n",
    "with torch.no_grad():\n",
    "    \n",
    "  inputs, target = next(iter(eval_loader))\n",
    "  # Reshape and get feature matrices as needed\n",
    "  print(inputs.shape)\n",
    "  inputs = inputs[0].permute(1, 2, 0)\n",
    "  # Save original Input\n",
    "  originalInput = inputs\n",
    "  for index, array in enumerate(inputs):\n",
    "    inputs[index] = np.squeeze(array)\n",
    "  inputs = torch.tensor(np.stack(feature_extractor(inputs)['pixel_values'], axis=0))\n",
    "\n",
    "  # Send to appropriate computing device\n",
    "  inputs = inputs.to(device)\n",
    "  target = target.to(device)\n",
    " \n",
    "  # Generate prediction\n",
    "  prediction, loss = model(inputs, target)\n",
    "    \n",
    "  # Predicted class value using argmax\n",
    "  predicted_class = np.argmax(prediction.cpu())\n",
    "  value_predicted = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(predicted_class)]\n",
    "  value_target = list(valid_ds.class_to_idx.keys())[list(valid_ds.class_to_idx.values()).index(target)]\n",
    "        \n",
    "  # Show result\n",
    "  plt.imshow(originalInput)\n",
    "  plt.xlim(224,0)\n",
    "  plt.ylim(224,0)\n",
    "  plt.title(f'Prediction: {value_predicted} - Actual target: {value_target}')\n",
    "  plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}